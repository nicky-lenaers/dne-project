{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWc4kcBMGnpg"
      },
      "source": [
        "# Play BlackJack using Random Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_ixzdtHHYg_a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9lmQIv9F9Ke"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSgELpG0YrrI",
        "outputId": "22e582be-6148-4dc2-dfaf-5f7a6296dbb3"
      },
      "outputs": [],
      "source": [
        "#!pip install gymnasium==0.29.1 pygame==2.3.0 pettingzoo==1.24.3 tianshou==0.5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJUqMfTpGHkb"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8eNTgrS7Qozg"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import tianshou as ts\n",
        "from gymnasium.wrappers import FlattenObservation\n",
        "\n",
        "# We keep an original copy of the environment that\n",
        "# is purely used for sampling as Tianshou modifies\n",
        "# the action space such that we cannot sample from\n",
        "# it.\n",
        "env_for_sampling = gym.make(\"Blackjack-v1\")\n",
        "\n",
        "def get_env(render_mode = None):\n",
        "  \"\"\"\n",
        "  BlackJack has an observation space which is a tuple, consisting of\n",
        "  the player's sum, the dealers card showing and whether or not\n",
        "  the player has a usable ace. This tuple is flattened for Tianshou\n",
        "  to be able to put it through the deep network layers.\n",
        "  \"\"\"\n",
        "  env = gym.make(\"Blackjack-v1\", render_mode=render_mode)\n",
        "  env = FlattenObservation(env)\n",
        "  env.reset(seed=42)\n",
        "\n",
        "  return env\n",
        "\n",
        "env = get_env()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4_YveVRRC87"
      },
      "source": [
        "# Create Policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ-3vuAuREa8",
        "outputId": "fea21246-d051-4b9b-c852-a5e31a7f3da8"
      },
      "outputs": [],
      "source": [
        "from tianshou.policy import BasePolicy\n",
        "from tianshou.data import Batch\n",
        "\n",
        "\n",
        "class RandomPolicy(BasePolicy):\n",
        "  def forward(self, batch, state):\n",
        "    \"\"\"\n",
        "    Sample a random action from the environment.\n",
        "    \"\"\"\n",
        "    return Batch(act=[env_for_sampling.action_space.sample()])\n",
        "  \n",
        "  def learn():\n",
        "    pass\n",
        "  \n",
        "policy = RandomPolicy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxLtBMTBKNg-"
      },
      "source": [
        "# Play\n",
        "\n",
        "Play with the trained agent to the opponent a number of episodes and print the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAhLVoCMctbb",
        "outputId": "28128abc-3b79-4307-adb5-30a1050f39ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Win: 28 lost: 70 draw: 2\n"
          ]
        }
      ],
      "source": [
        "policy.eval()\n",
        "\n",
        "env = get_env(render_mode=None)\n",
        "env = ts.env.DummyVectorEnv([lambda: env])\n",
        "collector = ts.data.Collector(policy, env, exploration_noise=True)\n",
        "result = collector.collect(n_episode=100, render=None)\n",
        "rews, lens = result[\"rews\"], result[\"lens\"]\n",
        "\n",
        "won = 0\n",
        "draw = 0\n",
        "lost = 0\n",
        "for res in result['rews']:\n",
        "  if res == 1:\n",
        "    won += 1\n",
        "  elif res == -1:\n",
        "    lost +=1\n",
        "  else:\n",
        "    draw += 1\n",
        "\n",
        "print(\"Win: \" + str(won) + \" lost: \" + str(lost) + \" draw: \" + str(draw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX5mHWKuUvjf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
